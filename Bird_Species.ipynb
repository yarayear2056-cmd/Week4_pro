{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSVkGExo936L9Ix+gt3PjG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yarayear2056-cmd/Week4_pro/blob/main/Bird_Species.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkO3AUXEeqcj",
        "outputId": "31c9c7a6-3f01-460f-a563-f94b293182fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.models import ResNet18_Weights\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy"
      ],
      "metadata": {
        "id": "iT4gu4VHewNc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgQm3x18e9iG",
        "outputId": "564e3ec0-c8be-4507-a69c-652250032aa4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"pavangawande/indian-bird-species-dataset-traintest-split\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxm2cwPsfB3A",
        "outputId": "c151ad89-2720-475d-d139-959a417bf7e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'indian-bird-species-dataset-traintest-split' dataset.\n",
            "Path to dataset files: /kaggle/input/indian-bird-species-dataset-traintest-split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FzZwgF0lVwq",
        "outputId": "5410e654-0f7c-42e2-a3a5-1f0a25382f46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Birds25_Split']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = os.path.join(path, os.listdir(path)[0])\n",
        "print(os.listdir(base_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QdGWlDuidSc",
        "outputId": "2eae6261-4ea9-40a2-9677-d7d2ccfeae1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "VyCD2NNJh_sJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(base_path,\"train\")\n",
        "test_path = os.path.join(base_path,\"test\")"
      ],
      "metadata": {
        "id": "mNxipPchltru"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "train_data = datasets.ImageFolder(train_path, transform=transform)\n",
        "test_data = datasets.ImageFolder(test_path, transform=transform)\n",
        "#data loader\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "z_CaYts6lwnP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for small data\n",
        "small_train_data = Subset(train_data, range(1000))\n",
        "small_test_data = Subset(test_data, range(500))\n",
        "\n",
        "small_train_loader = DataLoader(small_train_data, batch_size=32, shuffle=True)\n",
        "small_test_loader = DataLoader(small_test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "Wczsoobxlysn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "num_classes = len(train_data.classes)\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi6UAAmxl1Nc",
        "outputId": "20695721-adbd-403f-f391-31c4d7c1ac29"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 145MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(freeze_backbone=True):\n",
        "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "    if freeze_backbone:\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model.to(device)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-1h1NqJNpRPF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    loss_sum, correct, total = 0,0,0\n",
        "\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out,y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_sum += loss.item()\n",
        "        pred = out.argmax(1)\n",
        "        correct += (pred==y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return loss_sum/len(loader), correct/total\n",
        "\n",
        "\n",
        "def eval_one_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    loss_sum, correct, total = 0,0,0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out,y)\n",
        "\n",
        "            loss_sum += loss.item()\n",
        "            pred = out.argmax(1)\n",
        "            correct += (pred==y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return loss_sum/len(loader), correct/total"
      ],
      "metadata": {
        "id": "mHTEP5SPpTQx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_research_experiment(name, model, train_loader, val_loader, epochs=3):\n",
        "    print(f\"\\n===== Experiment: {name} =====\")\n",
        "\n",
        "    params = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = optim.SGD(params, lr=0.001, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    since = time.time()\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    history = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch}/{epochs-1}\")\n",
        "        print(\"-\"*10)\n",
        "\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, val_acc = eval_one_epoch(model, val_loader, criterion)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"train Loss: {train_loss:.4f} Acc: {train_acc:.4f}\")\n",
        "        print(f\"val   Loss: {val_loss:.4f} Acc: {val_acc:.4f}\\n\")\n",
        "\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f\"Training complete in {int(time_elapsed//60)}m {int(time_elapsed%60)}s\")\n",
        "    print(f\"Best val Acc: {best_acc:.6f}\")\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "1fFJNOu3pWjn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freeze_small = get_model(freeze_backbone=True)\n",
        "\n",
        "run_research_experiment(\n",
        "    \"freeze + small data\",\n",
        "    freeze_small,\n",
        "    small_train_loader,\n",
        "    small_test_loader\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgwdZV8rqT6w",
        "outputId": "0befc333-2692-412b-af66-d9f93b8b9612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Experiment: freeze + small data =====\n",
            "Epoch 0/2\n",
            "----------\n",
            "train Loss: 0.2998 Acc: 0.9470\n",
            "val   Loss: 7.1594 Acc: 0.5960\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freeze_large = get_model(freeze_backbone=True)\n",
        "run_research_experiment(\n",
        "    \"freeze + large data\",\n",
        "    freeze_large,\n",
        "    train_loader,\n",
        "    test_loader\n",
        ")"
      ],
      "metadata": {
        "id": "xsHLXSBUqhBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unfreeze_small = get_model(freeze_backbone=False)\n",
        "run_research_experiment(\n",
        "    \"unfreeze + small data\",\n",
        "    unfreeze_small,\n",
        "    small_train_loader,\n",
        "    small_test_loader\n",
        ")"
      ],
      "metadata": {
        "id": "gkOBC0poqkAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unfreeze_large = get_model(freeze_backbone=False)\n",
        "run_research_experiment(\n",
        "    \"unfreeze + large data\",\n",
        "    unfreeze_large,\n",
        "    train_loader,\n",
        "    test_loader\n",
        ")"
      ],
      "metadata": {
        "id": "EAU4Bjp4qmk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.plot(freeze_small[\"val_acc\"], label=\"Freeze Small\")\n",
        "plt.plot(freeze_large[\"val_acc\"], label=\"Freeze Large\")\n",
        "plt.plot(unfreeze_small[\"val_acc\"], label=\"Unfreeze Small\")\n",
        "plt.plot(unfreeze_large[\"val_acc\"], label=\"Unfreeze Large\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Transfer Learning Comparison\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X8W2oSJWpr9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(loader, class_names, n=6):\n",
        "    images, labels = next(iter(loader))\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for i in range(n):\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        img = images[i].permute(1,2,0)\n",
        "        plt.imshow(img)\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2v3SuTnj1Xk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(train_loader, class_names)"
      ],
      "metadata": {
        "id": "9pjaDIG81fnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    plt.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
        "    plt.plot(history[\"val_acc\"], label=\"Val Acc\")\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9O4YFqxD1ls6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(freeze_small, \"Freeze + Small Data\")"
      ],
      "metadata": {
        "id": "iXIvoaFL1n9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, loader, class_names):\n",
        "    model.eval()\n",
        "    images, labels = next(iter(loader))\n",
        "    images = images.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    for i in range(6):\n",
        "        plt.subplot(2,3,i+1)\n",
        "        img = images[i].cpu().permute(1,2,0)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Pred: {class_names[preds[i]]}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wKaJFY-E1vk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_predictions(best_model, test_loader, class_names)"
      ],
      "metadata": {
        "id": "FMLomCBd1yhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNK5DfWZ4giZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}